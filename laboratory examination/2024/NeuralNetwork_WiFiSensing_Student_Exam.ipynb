{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NnOoFtyHilj"
      },
      "source": [
        "# Human Activity Recognition Using WiFi Signals\n",
        "\n",
        "## Overview\n",
        "Human Activity Recognition (HAR) using WiFi signals leverages the unique properties of wireless channel variations to detect different activities.\n",
        "\n",
        "## Data Format\n",
        "- **WiFi signal data** is similar to image data in structure, represented in the shape `(channels, height, width)`, but with a different interpretation:\n",
        "  - `channels` → **channel**\n",
        "  - `height` → **Time Steps**\n",
        "  - `width` → **Antenna Pairs (transmitter-receiver combinations)**\n",
        "- **Labels** represent a predefined set of classes, as is typical in classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GqPqJNJIWNg"
      },
      "source": [
        "# Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "id": "3DwIkG1iHVPg",
        "outputId": "7382002b-2377-49e6-8e2a-08dfc09947e7"
      },
      "outputs": [
        {
          "ename": "FileURLRetrievalError",
          "evalue": "Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=17Vfiu90uYeeRqmW-QbhocgBt69mrrScA\n\nbut Gdown can't. Please check connections and permissions.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_url_from_gdrive_confirmation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mget_url_from_gdrive_confirmation\u001b[0;34m(contents)\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Too many users have viewed or downloaded this file recently. Please try accessing the file again later. If the file you are trying to access is particularly large or is shared with many people, it may take up to 24 hours to be able to view or download the file. If you still can't access a file after 24 hours, contact your domain administrator.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-3bb163107908>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Download the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"WiFiSensingDataset.pt.zip\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gdown/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(url, output, quiet, proxy, speed, use_cookies, verify, id, fuzzy, resume, format, user_agent, log_messages)\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0murl_origin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m             )\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileURLRetrievalError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0mfilename_from_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileURLRetrievalError\u001b[0m: Failed to retrieve file url:\n\n\tToo many users have viewed or downloaded this file recently. Please\n\ttry accessing the file again later. If the file you are trying to\n\taccess is particularly large or is shared with many people, it may\n\ttake up to 24 hours to be able to view or download the file. If you\n\tstill can't access a file after 24 hours, contact your domain\n\tadministrator.\n\nYou may still be able to access the file from the browser:\n\n\thttps://drive.google.com/uc?id=17Vfiu90uYeeRqmW-QbhocgBt69mrrScA\n\nbut Gdown can't. Please check connections and permissions."
          ]
        }
      ],
      "source": [
        "!pip install -U -q gdown\n",
        "\n",
        "import gdown\n",
        "\n",
        "link = \"https://drive.google.com/file/d/17Vfiu90uYeeRqmW-QbhocgBt69mrrScA/view?usp=sharing\"\n",
        "file_id = link.split('/d/')[1].split('/')[0]\n",
        "\n",
        "# Construct the direct download URL\n",
        "download_url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "\n",
        "# Download the file\n",
        "output_file = \"WiFiSensingDataset.pt.zip\"\n",
        "gdown.download(download_url, output_file, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zg4A9hDI48T",
        "outputId": "8c1ec96a-0e82-46e3-faec-83f9536a0447"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  WiFiSensingDataset.pt.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of WiFiSensingDataset.pt.zip or\n",
            "        WiFiSensingDataset.pt.zip.zip, and cannot find WiFiSensingDataset.pt.zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!unzip WiFiSensingDataset.pt.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tLL6yxBLARGk"
      },
      "outputs": [],
      "source": [
        "# Note: We're using torch modules (datasets, dataloaders) to download dataset and easily make batches.\n",
        "# The NN will be made in numpy and every step will be implemented ourselves\n",
        "\n",
        "# %%\n",
        "# Import necessary libraries.\n",
        "import numpy as np\n",
        "\n",
        "# Import MNIST dataset and DataLoader from Torchvision. This allows us to easily load and work with the MNIST dataset.\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Import the 'to_tensor' function for converting PIL images to tensors. This is necessary because PyTorch works with tensors.\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# Import Matplotlib's pyplot for visualizations. We'll use this to display images and plots.\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaOt9wMZI1nn",
        "outputId": "bb81dd33-8191-4330-ea70-6ce5b6c2da43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jawadkc66/q2-kaust-2025?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 204M/204M [00:05<00:00, 37.2MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/jawadkc66/q2-kaust-2025/versions/1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-26-7c3c69014005>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  data = torch.load('/root/.cache/kagglehub/datasets/jawadkc66/q2-kaust-2025/versions/1/WiFiSensingDataset.pt')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"jawadkc66/q2-kaust-2025\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "data = torch.load('/root/.cache/kagglehub/datasets/jawadkc66/q2-kaust-2025/versions/1/WiFiSensingDataset.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKv4rUCekmwu",
        "outputId": "96eea4f8-d3e7-4acb-a163-da336b12755c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'X_test': tensor([[[[0.4063, 0.1338, 0.4588,  ..., 0.6775, 0.7083, 0.6615],\n",
              "           [0.3715, 0.2196, 0.4792,  ..., 0.6935, 0.6967, 0.6641],\n",
              "           [0.3742, 0.2473, 0.4946,  ..., 0.7042, 0.7097, 0.6790],\n",
              "           ...,\n",
              "           [0.5245, 0.4429, 0.3430,  ..., 0.7161, 0.7224, 0.6850],\n",
              "           [0.4956, 0.4228, 0.3719,  ..., 0.7076, 0.6951, 0.6784],\n",
              "           [0.4861, 0.3396, 0.3864,  ..., 0.7166, 0.7392, 0.6788]]],\n",
              " \n",
              " \n",
              "         [[[0.5485, 0.5999, 0.6332,  ..., 0.7803, 0.7650, 0.7257],\n",
              "           [0.5426, 0.5947, 0.6169,  ..., 0.7856, 0.7601, 0.7224],\n",
              "           [0.5658, 0.6009, 0.6354,  ..., 0.7856, 0.7708, 0.7141],\n",
              "           ...,\n",
              "           [0.5661, 0.6048, 0.6422,  ..., 0.7963, 0.7836, 0.7276],\n",
              "           [0.5395, 0.6129, 0.6306,  ..., 0.7933, 0.7771, 0.7327],\n",
              "           [0.5523, 0.5882, 0.6299,  ..., 0.7900, 0.7739, 0.7293]]],\n",
              " \n",
              " \n",
              "         [[[0.3518, 0.4836, 0.4677,  ..., 0.8025, 0.7917, 0.7716],\n",
              "           [0.4130, 0.4547, 0.4947,  ..., 0.8142, 0.7906, 0.7653],\n",
              "           [0.4119, 0.4632, 0.5011,  ..., 0.7962, 0.7977, 0.7453],\n",
              "           ...,\n",
              "           [0.4476, 0.4848, 0.4603,  ..., 0.8009, 0.7937, 0.7510],\n",
              "           [0.4313, 0.4796, 0.5078,  ..., 0.8021, 0.7790, 0.7577],\n",
              "           [0.4664, 0.4507, 0.4557,  ..., 0.7999, 0.7948, 0.7412]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0.3576, 0.3716, 0.4629,  ..., 0.7683, 0.7666, 0.7621],\n",
              "           [0.2200, 0.2692, 0.4988,  ..., 0.7696, 0.7813, 0.7444],\n",
              "           [0.1683, 0.3531, 0.5505,  ..., 0.7591, 0.7936, 0.7436],\n",
              "           ...,\n",
              "           [0.6513, 0.6223, 0.6524,  ..., 0.6487, 0.6314, 0.6023],\n",
              "           [0.6346, 0.6073, 0.6269,  ..., 0.6551, 0.6167, 0.5842],\n",
              "           [0.6494, 0.5845, 0.6663,  ..., 0.6764, 0.6471, 0.5838]]],\n",
              " \n",
              " \n",
              "         [[[0.3932, 0.5839, 0.5014,  ..., 0.9296, 0.7705, 0.7355],\n",
              "           [0.3892, 0.5936, 0.4899,  ..., 0.9323, 0.7967, 0.7201],\n",
              "           [0.3817, 0.5714, 0.4761,  ..., 0.9343, 0.7767, 0.7218],\n",
              "           ...,\n",
              "           [0.2492, 0.4894, 0.3989,  ..., 0.8397, 0.6663, 0.6404],\n",
              "           [0.2035, 0.4521, 0.2779,  ..., 0.8419, 0.6882, 0.6354],\n",
              "           [0.1877, 0.4128, 0.3429,  ..., 0.8454, 0.6681, 0.6456]]],\n",
              " \n",
              " \n",
              "         [[[0.5169, 0.8046, 0.5107,  ..., 0.9392, 0.6567, 0.6159],\n",
              "           [0.5091, 0.8025, 0.5426,  ..., 0.9478, 0.6677, 0.5972],\n",
              "           [0.5129, 0.7894, 0.5407,  ..., 0.9379, 0.6472, 0.5938],\n",
              "           ...,\n",
              "           [0.4086, 0.7455, 0.5057,  ..., 0.9397, 0.6690, 0.6103],\n",
              "           [0.4655, 0.7614, 0.4939,  ..., 0.9387, 0.6515, 0.5977],\n",
              "           [0.4785, 0.7844, 0.4999,  ..., 0.9260, 0.6573, 0.5807]]]]),\n",
              " 'X_train': tensor([[[[0.5931, 0.6234, 0.6664,  ..., 0.8558, 0.8676, 0.8395],\n",
              "           [0.5971, 0.6378, 0.6707,  ..., 0.8611, 0.8697, 0.8310],\n",
              "           [0.6177, 0.6463, 0.7014,  ..., 0.8671, 0.8882, 0.8355],\n",
              "           ...,\n",
              "           [0.5660, 0.6178, 0.6437,  ..., 0.8034, 0.8093, 0.7637],\n",
              "           [0.5688, 0.5915, 0.6619,  ..., 0.8008, 0.8138, 0.7581],\n",
              "           [0.5595, 0.6065, 0.6748,  ..., 0.8052, 0.8233, 0.7676]]],\n",
              " \n",
              " \n",
              "         [[[0.5220, 0.5388, 0.5787,  ..., 0.7684, 0.7890, 0.7382],\n",
              "           [0.5211, 0.5279, 0.5596,  ..., 0.7596, 0.7905, 0.7388],\n",
              "           [0.5103, 0.5240, 0.5150,  ..., 0.7715, 0.7673, 0.7531],\n",
              "           ...,\n",
              "           [0.5267, 0.5472, 0.5706,  ..., 0.7756, 0.7785, 0.7378],\n",
              "           [0.5285, 0.5403, 0.5952,  ..., 0.7585, 0.7750, 0.7280],\n",
              "           [0.5204, 0.5663, 0.5723,  ..., 0.7658, 0.7716, 0.7447]]],\n",
              " \n",
              " \n",
              "         [[[0.5269, 0.3803, 0.5683,  ..., 0.7597, 0.7634, 0.7370],\n",
              "           [0.5132, 0.4223, 0.5921,  ..., 0.7803, 0.7726, 0.7488],\n",
              "           [0.5194, 0.3917, 0.5776,  ..., 0.7802, 0.7822, 0.7389],\n",
              "           ...,\n",
              "           [0.6301, 0.6589, 0.7244,  ..., 0.7481, 0.7587, 0.7165],\n",
              "           [0.6784, 0.6870, 0.7562,  ..., 0.7673, 0.7829, 0.7350],\n",
              "           [0.6772, 0.7130, 0.7709,  ..., 0.7888, 0.7750, 0.7567]]],\n",
              " \n",
              " \n",
              "         ...,\n",
              " \n",
              " \n",
              "         [[[0.4552, 0.4701, 0.4518,  ..., 0.7627, 0.7260, 0.7017],\n",
              "           [0.4510, 0.4539, 0.4680,  ..., 0.7658, 0.7467, 0.6873],\n",
              "           [0.4726, 0.4791, 0.4577,  ..., 0.7637, 0.7276, 0.6952],\n",
              "           ...,\n",
              "           [0.6184, 0.6350, 0.6435,  ..., 0.7921, 0.7995, 0.7435],\n",
              "           [0.6314, 0.6495, 0.6705,  ..., 0.7955, 0.8127, 0.7490],\n",
              "           [0.6347, 0.6501, 0.6485,  ..., 0.8240, 0.8123, 0.7713]]],\n",
              " \n",
              " \n",
              "         [[[0.4525, 0.5108, 0.4933,  ..., 0.8108, 0.7894, 0.7809],\n",
              "           [0.4439, 0.5042, 0.5226,  ..., 0.8034, 0.8099, 0.7532],\n",
              "           [0.4861, 0.5073, 0.4874,  ..., 0.8033, 0.7922, 0.7790],\n",
              "           ...,\n",
              "           [0.5681, 0.5712, 0.5650,  ..., 0.8260, 0.8156, 0.7914],\n",
              "           [0.5283, 0.5525, 0.5790,  ..., 0.8241, 0.8163, 0.7958],\n",
              "           [0.5592, 0.6028, 0.5930,  ..., 0.8242, 0.8168, 0.7940]]],\n",
              " \n",
              " \n",
              "         [[[0.4707, 0.4942, 0.5336,  ..., 0.7695, 0.7696, 0.7393],\n",
              "           [0.4660, 0.5158, 0.5476,  ..., 0.7733, 0.7720, 0.7415],\n",
              "           [0.4900, 0.4933, 0.5147,  ..., 0.7606, 0.7728, 0.7338],\n",
              "           ...,\n",
              "           [0.4940, 0.5088, 0.5460,  ..., 0.7620, 0.7791, 0.7266],\n",
              "           [0.4624, 0.5207, 0.5479,  ..., 0.7745, 0.7776, 0.7458],\n",
              "           [0.4936, 0.5078, 0.5261,  ..., 0.7644, 0.7582, 0.7374]]]]),\n",
              " 'y_test': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
              "         1., 1., 1., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "         3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
              "         3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
              "         4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 5., 5., 5., 5., 5., 5.,\n",
              "         5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.,\n",
              "         5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 6., 6.,\n",
              "         6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.,\n",
              "         6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "         2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]),\n",
              " 'y_train': tensor([2., 1., 2.,  ..., 0., 4., 1.])}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch  # Import the PyTorch library\n",
        "\n",
        "import torch.nn as nn  # Import the neural network module from PyTorch\n",
        "\n",
        "from torchvision.datasets import MNIST  # Import MNIST dataset from Torchvision\n",
        "from torch.utils.data import DataLoader  # Import DataLoader for batching\n",
        "from torch.optim import Adam  # Import the Adam optimizer\n",
        "\n",
        "from torchvision.transforms.functional import to_tensor  # Import to_tensor for image conversion\n",
        "\n",
        "import matplotlib.pyplot as plt  # Import Matplotlib for visualization\n",
        "data\n",
        "import pandas as pd\n",
        "data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vkoyStvJBLl"
      },
      "source": [
        "# Task 1: Analyze the Dataset ( Stored in `data`)\n",
        "\n",
        "1. **Determine the number of unique labels** in the dataset.  \n",
        "\n",
        "2. **Determine the shape of the input data** (number of samples and features).  \n",
        "\n",
        "3. **Find the maximum value** in the dataset.  \n",
        "\n",
        "4. **Find the minimum value** in the dataset.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lPNBr_UK1nb",
        "outputId": "bc0f0e61-ecf8-4719-dd4c-b0d0b455c9bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(set(data))  #number of unique labels\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbbW9TqJJI84"
      },
      "source": [
        "# Task 2: Build and Evaluate a Neural Network\n",
        "\n",
        "1. **Design a Neural Network (Maximum 5 Layers)**  \n",
        "   Build a compact neural network with no more than 5 layers. Clearly specify the type of each layer (e.g., Dense, Conv2D) and any activation functions used.\n",
        "\n",
        "2. **Evaluate Your Model**  \n",
        "   Train your network on the provided dataset and report the evaluation metrics (e.g., accuracy, loss). Discuss the performance of your model and any challenges faced during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hci0PeriJIGD"
      },
      "outputs": [],
      "source": [
        "ni=5\n",
        "nh=10\n",
        "no=10\n",
        "w1=np.random.randn(nh,ni)\n",
        "b1=np.zeros((nh,1))\n",
        "w2=np.random.randn(no,nh)\n",
        "b2=np.zeros((no,1))\n",
        "w3=np.random.randn((no,nh))\n",
        "b3=np.zeros((no,1))\n",
        "w4=np.random.randn((no,nh))\n",
        "b4=np.zeros((no,1))\n",
        "w5=np.random.randn((no,nh))\n",
        "b5=np.zeros((no,1))\n",
        "num_epochs = 12              # Number of training epochs\n",
        "lr = 1e-2                    # Learning rate for gradient descent\n",
        "train_epoch_losses = []      # List to store training loss for each epoch\n",
        "\n",
        "total_train_imgs = len(train_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAMgZ-FXJIL9"
      },
      "outputs": [],
      "source": [
        "epoch_loss = 0  # Initialize total loss for the epoch\n",
        "correct = 0    # Initialize count of correctly classified images\n",
        "\n",
        "for X, labels in train_loader:  # Iterate over batches of data\n",
        "\n",
        "    # Preprocess the data\n",
        "    X = X.numpy().reshape(-1, 28*28).T  # Convert images to numpy arrays and reshape (transpose)\n",
        "    labels = labels.numpy()           # Convert labels to numpy arrays\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    y = np.zeros((no, X.shape[1]))       # Create a matrix of zeros with shape (no, batch_size)\n",
        "    y[labels, np.arange(y.shape[1])] = 1  # Set the corresponding element to 1 for each label\n",
        "\n",
        "    # Forward pass\n",
        "    Z1 = W1 @ X + b1   # Calculate weighted sum and add bias for the first layer\n",
        "    A1 = sigmoid(Z1)   # Apply sigmoid activation to get the output of the first layer\n",
        "    Z2 = W2 @ A1 + b2   # Calculate weighted sum and add bias for the second layer\n",
        "    yhat = sigmoid(Z2)  # Apply sigmoid activation to get the predicted probabilities\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = cross_entropy_loss(yhat, y)  # Calculate the cross-entropy loss\n",
        "    epoch_loss += loss * len(labels)   # Accumulate the loss for the batch\n",
        "\n",
        "    # Calculate accuracy\n",
        "    pred = np.argmax(yhat, axis=0)    # Get the predicted class labels\n",
        "    correct += np.sum(labels == pred)  # Count the number of correct predictions\n",
        "\n",
        "# Calculate average epoch loss\n",
        "epoch_loss /= total_train_imgs\n",
        "train_epoch_losses.append(epoch_loss)  # Store the epoch loss\n",
        "\n",
        "# Print the loss and accuracy for the epoch\n",
        "print(f'loss = {epoch_loss}. {correct}/{total_train_imgs} correctly labelled.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PHWz6VtLLT1"
      },
      "outputs": [],
      "source": [
        "for i in range(num_epochs):  # Loop over the specified number of epochs\n",
        "\n",
        "    epoch_loss = 0  # Initialize total loss for the epoch\n",
        "    correct = 0    # Initialize count of correctly classified images\n",
        "\n",
        "    for X, labels in train_loader:  # Iterate over batches of data\n",
        "\n",
        "        # Preprocess the data (same as before)\n",
        "        X = X.numpy().reshape(-1, 28*28).T\n",
        "        labels = labels.numpy()\n",
        "\n",
        "        y = np.zeros((no, X.shape[1]))\n",
        "        y[labels, np.arange(y.shape[1])] = 1\n",
        "\n",
        "        # Forward pass (same as before)\n",
        "        Z1 = W1 @ X + b1\n",
        "        A1 = sigmoid(Z1)\n",
        "\n",
        "        Z2 = W2 @ A1 + b2\n",
        "        yhat = sigmoid(Z2)\n",
        "\n",
        "        # --------------------\n",
        "        # Backward pass\n",
        "        # --------------------\n",
        "\n",
        "        # Calculate gradients\n",
        "        dZ2 = yhat - y                                  # Gradient of loss w.r.t Z2\n",
        "        dW2 = dZ2 @ A1.T                                # Gradient of loss w.r.t W2\n",
        "        db2 = np.sum(dZ2, axis=1, keepdims=True)         # Gradient of loss w.r.t b2\n",
        "\n",
        "        dZ1 = W2.T @ dZ2 * A1 * (1 - A1)                # Gradient of loss w.r.t Z1\n",
        "        dW1 = dZ1 @ X.T                                # Gradient of loss w.r.t W1\n",
        "        db1 = np.sum(dZ1, axis=1, keepdims=True)         # Gradient of loss w.r.t b1\n",
        "\n",
        "        # --------------------\n",
        "        # Optimization (update weights and biases)\n",
        "        # --------------------\n",
        "        W2 -= lr * dW2\n",
        "        b2 -= lr * db2\n",
        "        W1 -= lr * dW1\n",
        "        b1 -= lr * db1\n",
        "\n",
        "        # Calculate classification error (same as before)\n",
        "        pred = np.argmax(yhat, axis=0)\n",
        "        correct += np.sum(labels == pred)\n",
        "\n",
        "        loss = cross_entropy_loss(yhat, y)\n",
        "        epoch_loss += loss * len(labels)\n",
        "\n",
        "    # Calculate average epoch loss and print results (same as before)\n",
        "    epoch_loss /= total_train_imgs\n",
        "    train_epoch_losses.append(epoch_loss)\n",
        "\n",
        "    print(f'Epoch {i}, loss = {epoch_loss}. {correct}/{total_train_imgs} correctly labelled.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pqoK28DLPB4"
      },
      "source": [
        "Good luck in the exam x)\n",
        "\n",
        "Prepared by: Ahmed Y. Radwan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5er_pdi8w5cV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
